{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MTCNN f√ºr Gesichtserkennung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from mtcnn import MTCNN\n",
    "import tensorflow as tf\n",
    "\n",
    "# Basispfade\n",
    "basis_bildordner = \"C:/Thesis/Data/Frames/Fullbody_sorted_Body_Language/\"\n",
    "basis_emotionsordner = \"C:/Thesis/Data/Frames/Mimik/\"\n",
    "\n",
    "# Emotionsliste\n",
    "emotionen = [\"Freude\", \"Ekel\", \"Trauer\", \"Wut\", \"Angst\"]\n",
    "\n",
    "# Initialisiere MTCNN-Detektor\n",
    "detector = MTCNN()\n",
    "\n",
    "# Iteriere durch jede Emotion\n",
    "for emotion in emotionen:\n",
    "    bildordner = os.path.join(basis_bildordner, emotion)\n",
    "    emotionsordner = os.path.join(basis_emotionsordner, emotion)\n",
    "\n",
    "    # Stelle sicher, dass der Ordner existiert\n",
    "    if not os.path.exists(emotionsordner):\n",
    "        os.makedirs(emotionsordner)\n",
    "\n",
    "    # Liste alle Bilddateien im Bildordner auf\n",
    "    bilder = [datei for datei in os.listdir(bildordner) if datei.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    # Verarbeite jedes Bild\n",
    "    for bild_datei in bilder:\n",
    "        bild_pfad = os.path.join(bildordner, bild_datei)\n",
    "\n",
    "        # Lade das Bild mit OpenCV\n",
    "        bild = cv2.imread(bild_pfad)\n",
    "\n",
    "        # Erkenne Gesichter im Bild\n",
    "        ergebnisse = detector.detect_faces(bild)\n",
    "\n",
    "        # Verarbeite jedes erkannte Gesicht\n",
    "        for ergebnis in ergebnisse:\n",
    "            x, y, w, h = ergebnis['box']\n",
    "            erweiterungsfaktor = 0.5\n",
    "            erweiterung_x = int(w * erweiterungsfaktor)\n",
    "            erweiterung_y = int(h * erweiterungsfaktor)\n",
    "            x_neu = max(0, x - erweiterung_x)\n",
    "            y_neu = max(0, y - erweiterung_y)\n",
    "            w_neu = min(bild.shape[1], w + 2 * erweiterung_x)\n",
    "            h_neu = min(bild.shape[0], h + 2 * erweiterung_y)\n",
    "\n",
    "            # Schneide den Ausschnitt aus dem Bild\n",
    "            ausschnitt = bild[y_neu:y_neu + h_neu, x_neu:x_neu + w_neu]\n",
    "\n",
    "            # Speichere den Ausschnitt im entsprechenden Emotionsordner\n",
    "            ausgabedatei = os.path.join(emotionsordner, f\"{bild_datei}_gesicht.jpg\")\n",
    "            cv2.imwrite(ausgabedatei, ausschnitt)\n",
    "\n",
    "print(\"Fertig!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_recogntion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
