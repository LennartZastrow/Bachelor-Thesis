{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code f√ºr Feature Extraktion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 79ms/step - loss: 2.3447 - accuracy: 0.2775 - val_loss: 1.7875 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.8801 - accuracy: 0.4393 - val_loss: 1.9673 - val_accuracy: 0.7083 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7225 - accuracy: 0.4971 - val_loss: 1.8947 - val_accuracy: 0.5417 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.5867 - accuracy: 0.5896 - val_loss: 1.9474 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5540 - accuracy: 0.5954 - val_loss: 2.0169 - val_accuracy: 0.5417 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4419 - accuracy: 0.6705 - val_loss: 1.8535 - val_accuracy: 0.5417 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3863 - accuracy: 0.6705 - val_loss: 1.8441 - val_accuracy: 0.5417 - lr: 2.0000e-05\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3474 - accuracy: 0.7225 - val_loss: 1.8378 - val_accuracy: 0.5417 - lr: 2.0000e-05\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4154 - accuracy: 0.6474 - val_loss: 1.8107 - val_accuracy: 0.5417 - lr: 2.0000e-05\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.3246 - accuracy: 0.7168 - val_loss: 1.7798 - val_accuracy: 0.5417 - lr: 2.0000e-05\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.3547 - accuracy: 0.6821 - val_loss: 1.7531 - val_accuracy: 0.5000 - lr: 2.0000e-05\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.3642 - accuracy: 0.7052 - val_loss: 1.7324 - val_accuracy: 0.5000 - lr: 2.0000e-05\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.2920 - accuracy: 0.7399 - val_loss: 1.6992 - val_accuracy: 0.5000 - lr: 2.0000e-05\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.3253 - accuracy: 0.6705 - val_loss: 1.6703 - val_accuracy: 0.5000 - lr: 2.0000e-05\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2866 - accuracy: 0.7283 - val_loss: 1.6552 - val_accuracy: 0.5000 - lr: 2.0000e-05\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2562 - accuracy: 0.6994 - val_loss: 1.6448 - val_accuracy: 0.5417 - lr: 2.0000e-05\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.2762 - accuracy: 0.6936 - val_loss: 1.6250 - val_accuracy: 0.5417 - lr: 2.0000e-05\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2797 - accuracy: 0.7457 - val_loss: 1.5730 - val_accuracy: 0.5833 - lr: 2.0000e-05\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2880 - accuracy: 0.7341 - val_loss: 1.5405 - val_accuracy: 0.5833 - lr: 2.0000e-05\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.2234 - accuracy: 0.7514 - val_loss: 1.5287 - val_accuracy: 0.5833 - lr: 2.0000e-05\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2612 - accuracy: 0.7341 - val_loss: 1.5255 - val_accuracy: 0.5417 - lr: 2.0000e-05\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1923 - accuracy: 0.7630 - val_loss: 1.5049 - val_accuracy: 0.5833 - lr: 2.0000e-05\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2221 - accuracy: 0.7225 - val_loss: 1.4873 - val_accuracy: 0.5833 - lr: 2.0000e-05\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.1982 - accuracy: 0.7514 - val_loss: 1.4633 - val_accuracy: 0.5833 - lr: 2.0000e-05\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2168 - accuracy: 0.7514 - val_loss: 1.4307 - val_accuracy: 0.5833 - lr: 2.0000e-05\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2122 - accuracy: 0.7514 - val_loss: 1.4157 - val_accuracy: 0.5417 - lr: 2.0000e-05\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1644 - accuracy: 0.7803 - val_loss: 1.4131 - val_accuracy: 0.5417 - lr: 2.0000e-05\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1198 - accuracy: 0.7977 - val_loss: 1.4048 - val_accuracy: 0.5833 - lr: 2.0000e-05\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.1773 - accuracy: 0.7803 - val_loss: 1.3724 - val_accuracy: 0.5833 - lr: 2.0000e-05\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1288 - accuracy: 0.7630 - val_loss: 1.3529 - val_accuracy: 0.6250 - lr: 2.0000e-05\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.2202 - accuracy: 0.7341 - val_loss: 1.3398 - val_accuracy: 0.6250 - lr: 2.0000e-05\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1655 - accuracy: 0.7630 - val_loss: 1.3289 - val_accuracy: 0.6250 - lr: 2.0000e-05\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.1845 - accuracy: 0.7688 - val_loss: 1.3243 - val_accuracy: 0.6250 - lr: 2.0000e-05\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1136 - accuracy: 0.8035 - val_loss: 1.3132 - val_accuracy: 0.6250 - lr: 2.0000e-05\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0754 - accuracy: 0.8266 - val_loss: 1.2963 - val_accuracy: 0.6250 - lr: 2.0000e-05\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0957 - accuracy: 0.8092 - val_loss: 1.2881 - val_accuracy: 0.6250 - lr: 2.0000e-05\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.1444 - accuracy: 0.7630 - val_loss: 1.2779 - val_accuracy: 0.6250 - lr: 2.0000e-05\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0815 - accuracy: 0.7803 - val_loss: 1.2736 - val_accuracy: 0.7083 - lr: 2.0000e-05\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0801 - accuracy: 0.8150 - val_loss: 1.2702 - val_accuracy: 0.6667 - lr: 2.0000e-05\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0531 - accuracy: 0.7803 - val_loss: 1.2665 - val_accuracy: 0.6250 - lr: 2.0000e-05\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0605 - accuracy: 0.7861 - val_loss: 1.2523 - val_accuracy: 0.6667 - lr: 2.0000e-05\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1128 - accuracy: 0.8092 - val_loss: 1.2448 - val_accuracy: 0.6667 - lr: 2.0000e-05\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0366 - accuracy: 0.8324 - val_loss: 1.2424 - val_accuracy: 0.6667 - lr: 2.0000e-05\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0092 - accuracy: 0.8497 - val_loss: 1.2259 - val_accuracy: 0.6667 - lr: 2.0000e-05\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0278 - accuracy: 0.7977 - val_loss: 1.2239 - val_accuracy: 0.6667 - lr: 2.0000e-05\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0494 - accuracy: 0.8035 - val_loss: 1.2327 - val_accuracy: 0.6667 - lr: 2.0000e-05\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0434 - accuracy: 0.7746 - val_loss: 1.2531 - val_accuracy: 0.6667 - lr: 2.0000e-05\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0157 - accuracy: 0.8035 - val_loss: 1.2296 - val_accuracy: 0.7083 - lr: 2.0000e-05\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0376 - accuracy: 0.8092 - val_loss: 1.2065 - val_accuracy: 0.7500 - lr: 2.0000e-05\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0113 - accuracy: 0.8266 - val_loss: 1.1994 - val_accuracy: 0.7083 - lr: 2.0000e-05\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0358 - accuracy: 0.8324 - val_loss: 1.2122 - val_accuracy: 0.7083 - lr: 2.0000e-05\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9690 - accuracy: 0.8324 - val_loss: 1.2161 - val_accuracy: 0.7083 - lr: 2.0000e-05\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9204 - accuracy: 0.8613 - val_loss: 1.1943 - val_accuracy: 0.7500 - lr: 2.0000e-05\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0043 - accuracy: 0.8092 - val_loss: 1.1920 - val_accuracy: 0.7083 - lr: 2.0000e-05\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9972 - accuracy: 0.8208 - val_loss: 1.2166 - val_accuracy: 0.7500 - lr: 2.0000e-05\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9624 - accuracy: 0.8555 - val_loss: 1.2062 - val_accuracy: 0.7083 - lr: 2.0000e-05\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9429 - accuracy: 0.8439 - val_loss: 1.1878 - val_accuracy: 0.7500 - lr: 2.0000e-05\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9638 - accuracy: 0.8555 - val_loss: 1.1906 - val_accuracy: 0.7500 - lr: 2.0000e-05\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9544 - accuracy: 0.8497 - val_loss: 1.1976 - val_accuracy: 0.7500 - lr: 2.0000e-05\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9166 - accuracy: 0.8671 - val_loss: 1.1979 - val_accuracy: 0.7917 - lr: 2.0000e-05\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9924 - accuracy: 0.8208 - val_loss: 1.1989 - val_accuracy: 0.7500 - lr: 2.0000e-05\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9410 - accuracy: 0.8092 - val_loss: 1.1866 - val_accuracy: 0.7500 - lr: 2.0000e-05\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9400 - accuracy: 0.8671 - val_loss: 1.1742 - val_accuracy: 0.7083 - lr: 2.0000e-05\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9905 - accuracy: 0.8092 - val_loss: 1.1941 - val_accuracy: 0.7500 - lr: 2.0000e-05\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9200 - accuracy: 0.8728 - val_loss: 1.1992 - val_accuracy: 0.7917 - lr: 2.0000e-05\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9122 - accuracy: 0.8671 - val_loss: 1.1711 - val_accuracy: 0.7500 - lr: 2.0000e-05\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9391 - accuracy: 0.8439 - val_loss: 1.1764 - val_accuracy: 0.7500 - lr: 2.0000e-05\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9217 - accuracy: 0.8497 - val_loss: 1.2213 - val_accuracy: 0.7917 - lr: 2.0000e-05\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9236 - accuracy: 0.8382 - val_loss: 1.1949 - val_accuracy: 0.7917 - lr: 2.0000e-05\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8705 - accuracy: 0.8844 - val_loss: 1.1410 - val_accuracy: 0.7917 - lr: 2.0000e-05\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9157 - accuracy: 0.8439 - val_loss: 1.1640 - val_accuracy: 0.7500 - lr: 2.0000e-05\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9102 - accuracy: 0.8613 - val_loss: 1.1744 - val_accuracy: 0.7917 - lr: 2.0000e-05\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8841 - accuracy: 0.8844 - val_loss: 1.1791 - val_accuracy: 0.7917 - lr: 2.0000e-05\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8687 - accuracy: 0.8786 - val_loss: 1.1439 - val_accuracy: 0.7917 - lr: 2.0000e-05\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8562 - accuracy: 0.8902 - val_loss: 1.1284 - val_accuracy: 0.7917 - lr: 2.0000e-05\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8789 - accuracy: 0.8497 - val_loss: 1.1412 - val_accuracy: 0.7500 - lr: 2.0000e-05\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9121 - accuracy: 0.8497 - val_loss: 1.1425 - val_accuracy: 0.7917 - lr: 2.0000e-05\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8996 - accuracy: 0.8497 - val_loss: 1.1378 - val_accuracy: 0.7917 - lr: 2.0000e-05\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9008 - accuracy: 0.8844 - val_loss: 1.1319 - val_accuracy: 0.7500 - lr: 2.0000e-05\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8500 - accuracy: 0.8728 - val_loss: 1.1680 - val_accuracy: 0.7917 - lr: 2.0000e-05\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9023 - accuracy: 0.8786 - val_loss: 1.1817 - val_accuracy: 0.7917 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8649 - accuracy: 0.8786 - val_loss: 1.1783 - val_accuracy: 0.7917 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8450 - accuracy: 0.8728 - val_loss: 1.1725 - val_accuracy: 0.7500 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8986 - accuracy: 0.8497 - val_loss: 1.1589 - val_accuracy: 0.7500 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8310 - accuracy: 0.9017 - val_loss: 1.1467 - val_accuracy: 0.7500 - lr: 1.0000e-05\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9189 - accuracy: 0.8235\n",
      "Test accuracy: 0.8235294222831726, Test loss: 0.9189059138298035\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, BatchNormalization, MaxPooling1D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Funktion zur Extraktion der Audio-Features\n",
    "def extract_audio_features(file_path, n_fft=512):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    chromagram = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "    features = np.hstack((np.mean(mfccs, axis=1), \n",
    "                          np.mean(librosa.power_to_db(mel_spectrogram), axis=1),\n",
    "                          np.mean(chromagram, axis=1),\n",
    "                          np.mean(spectral_contrast, axis=1),\n",
    "                          np.mean(tonnetz, axis=1)))\n",
    "    if len(features) > 193:\n",
    "        features = features[:193]\n",
    "    elif len(features) < 193:\n",
    "        features = np.pad(features, (0, 193 - len(features)), 'constant')\n",
    "    return features\n",
    "\n",
    "# Daten und Labels laden\n",
    "def load_data_and_labels(base_path):\n",
    "    emotions = {'Angst': 0, 'Ekel': 1, 'Trauer': 2, 'Freude': 3}\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    for emotion, label in emotions.items():\n",
    "        emotion_path = os.path.join(base_path, emotion)\n",
    "        for filename in os.listdir(emotion_path):\n",
    "            if filename.endswith(\".wav\"):\n",
    "                file_path = os.path.join(emotion_path, filename)\n",
    "                features = extract_audio_features(file_path)\n",
    "                features_list.append(features)\n",
    "                labels_list.append(label)\n",
    "    return np.array(features_list), np.array(labels_list)\n",
    "\n",
    "# CNN Modelldefinition mit L2-Regularisierung und erweiterten Schichten\n",
    "def build_model(input_shape, number_of_classes):\n",
    "    model = Sequential([\n",
    "        Conv1D(256, 5, input_shape=input_shape, padding='same', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(128, 5, padding='same', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Dropout(0.2),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(128, 5, padding='same', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.2),\n",
    "        Dense(number_of_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Hauptskript\n",
    "base_path = r'C:\\Users\\zastr\\Desktop\\Thesis\\Data\\Audio\\Emo_DB'\n",
    "features, labels = load_data_and_labels(base_path)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.67, random_state=42)\n",
    "\n",
    "model = build_model((193, 1), len(np.unique(labels)))\n",
    "\n",
    "# Callbacks zur Anpassung der Lernrate und zum fr√ºhzeitigen Stopp, falls keine Verbesserung mehr stattfindet\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Modelltraining mit Early Stopping und Learning Rate Reduction\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[reduce_lr, early_stopping])\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}, Test loss: {test_loss}')\n",
    "\n",
    "\n",
    "# Visualisierung der Merkmalsextraktion\n",
    "# Beispiel-Durchschnittsmerkmale f√ºr jede Emotion (hier simuliert)\n",
    "emotions = ['Angst', 'Ekel', 'Trauer', 'Freude']\n",
    "features = ['MFCCs', 'Mel-Spectrogram', 'Chromagram', 'Spectral Contrast', 'Tonnetz']\n",
    "\n",
    "# Simulierte durchschnittliche Merkmalswerte f√ºr jede Emotion\n",
    "avg_feature_values = np.random.rand(len(emotions), len(features)) * 10  # Beispielwerte zwischen 0 und 10\n",
    "\n",
    "# Farbpalette f√ºr die Emotionen\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(emotions)))\n",
    "\n",
    "# Erstellung des Balkendiagramms\n",
    "plt.figure(figsize=(10, 6))\n",
    "bar_width = 0.2  # Breite der Balken\n",
    "for i in range(len(emotions)):\n",
    "    plt.bar(np.arange(len(features)) + i * bar_width, avg_feature_values[i], bar_width, color=colors[i], label=emotions[i])\n",
    "\n",
    "# Hinzuf√ºgen von Beschriftungen und Legende\n",
    "plt.xlabel('Merkmale')\n",
    "plt.ylabel('Durchschnittliche Merkmalswerte')\n",
    "plt.title('Durchschnittliche Merkmalswerte f√ºr jede Emotion')\n",
    "plt.xticks(np.arange(len(features)) + bar_width * 1.5, features)  # X-Achsenbeschriftung anpassen\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Anpassen der Layout-Einstellungen\n",
    "plt.tight_layout()\n",
    "\n",
    "# Anzeige oder Speicherung der Visualisierung\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 32ms/step - loss: 2.1795 - accuracy: 0.2775 - val_loss: 1.9314 - val_accuracy: 0.4167 - lr: 1.0000e-04\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.8753 - accuracy: 0.4046 - val_loss: 1.8396 - val_accuracy: 0.4583 - lr: 1.0000e-04\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.6371 - accuracy: 0.5838 - val_loss: 1.8657 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.5339 - accuracy: 0.5838 - val_loss: 1.7621 - val_accuracy: 0.4583 - lr: 1.0000e-04\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4581 - accuracy: 0.6358 - val_loss: 1.7968 - val_accuracy: 0.4583 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3720 - accuracy: 0.6936 - val_loss: 1.8352 - val_accuracy: 0.4583 - lr: 1.0000e-04\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3360 - accuracy: 0.6763 - val_loss: 1.7917 - val_accuracy: 0.4583 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2713 - accuracy: 0.7052 - val_loss: 1.7428 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2932 - accuracy: 0.7052 - val_loss: 1.7990 - val_accuracy: 0.4583 - lr: 1.0000e-04\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.2543 - accuracy: 0.7457 - val_loss: 1.5674 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.1660 - accuracy: 0.7572 - val_loss: 1.6028 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2167 - accuracy: 0.6879 - val_loss: 1.5364 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1575 - accuracy: 0.7514 - val_loss: 1.4435 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1181 - accuracy: 0.7630 - val_loss: 1.4570 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1363 - accuracy: 0.7803 - val_loss: 1.3960 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.0838 - accuracy: 0.7919 - val_loss: 1.4138 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.0535 - accuracy: 0.8208 - val_loss: 1.3769 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.0355 - accuracy: 0.8150 - val_loss: 1.3527 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.0204 - accuracy: 0.7861 - val_loss: 1.3917 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9968 - accuracy: 0.8208 - val_loss: 1.3343 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.0318 - accuracy: 0.8092 - val_loss: 1.3143 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9501 - accuracy: 0.8439 - val_loss: 1.3032 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9614 - accuracy: 0.8035 - val_loss: 1.3016 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.9666 - accuracy: 0.8266 - val_loss: 1.2838 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8964 - accuracy: 0.8555 - val_loss: 1.2433 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.9473 - accuracy: 0.8035 - val_loss: 1.2396 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9227 - accuracy: 0.8497 - val_loss: 1.2136 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8995 - accuracy: 0.8497 - val_loss: 1.1831 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8877 - accuracy: 0.8613 - val_loss: 1.2333 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8434 - accuracy: 0.8902 - val_loss: 1.1711 - val_accuracy: 0.7083 - lr: 1.0000e-04\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8220 - accuracy: 0.8844 - val_loss: 1.1738 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8480 - accuracy: 0.9075 - val_loss: 1.1839 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7874 - accuracy: 0.9249 - val_loss: 1.1363 - val_accuracy: 0.7083 - lr: 1.0000e-04\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8022 - accuracy: 0.9249 - val_loss: 1.1807 - val_accuracy: 0.7083 - lr: 1.0000e-04\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8399 - accuracy: 0.8613 - val_loss: 1.1345 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8044 - accuracy: 0.8960 - val_loss: 1.1215 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7817 - accuracy: 0.9191 - val_loss: 1.1324 - val_accuracy: 0.7917 - lr: 1.0000e-04\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7404 - accuracy: 0.9075 - val_loss: 1.0828 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7396 - accuracy: 0.9017 - val_loss: 1.1446 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7359 - accuracy: 0.9191 - val_loss: 1.0766 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7405 - accuracy: 0.9306 - val_loss: 1.0829 - val_accuracy: 0.7917 - lr: 1.0000e-04\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7552 - accuracy: 0.9133 - val_loss: 1.0476 - val_accuracy: 0.7917 - lr: 1.0000e-04\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7732 - accuracy: 0.8960 - val_loss: 1.0759 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7931 - accuracy: 0.9017 - val_loss: 1.1181 - val_accuracy: 0.7917 - lr: 1.0000e-04\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7272 - accuracy: 0.9306 - val_loss: 1.0849 - val_accuracy: 0.7917 - lr: 1.0000e-04\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7240 - accuracy: 0.9133 - val_loss: 1.1280 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7400 - accuracy: 0.9191 - val_loss: 1.1518 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7315 - accuracy: 0.9249 - val_loss: 1.1263 - val_accuracy: 0.7500 - lr: 2.0000e-05\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6972 - accuracy: 0.9306 - val_loss: 1.1017 - val_accuracy: 0.6667 - lr: 2.0000e-05\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7120 - accuracy: 0.9422 - val_loss: 1.0897 - val_accuracy: 0.6667 - lr: 2.0000e-05\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6789 - accuracy: 0.9538 - val_loss: 1.0871 - val_accuracy: 0.7083 - lr: 2.0000e-05\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6798 - accuracy: 0.9538 - val_loss: 1.1181 - val_accuracy: 0.7500 - lr: 2.0000e-05\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8170 - accuracy: 0.9216\n",
      "Test accuracy: 0.9215686321258545, Test loss: 0.8169937133789062\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, BatchNormalization, MaxPooling1D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Funktion zur Extraktion der Audio-Features\n",
    "def extract_audio_features(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    chromagram = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "    features = np.hstack((np.mean(mfccs, axis=1), \n",
    "                          np.mean(librosa.power_to_db(mel_spectrogram), axis=1),\n",
    "                          np.mean(chromagram, axis=1),\n",
    "                          np.mean(spectral_contrast, axis=1),\n",
    "                          np.mean(tonnetz, axis=1)))\n",
    "    if len(features) > 193:\n",
    "        features = features[:193]\n",
    "    elif len(features) < 193:\n",
    "        features = np.pad(features, (0, 193 - len(features)), 'constant')\n",
    "    return features\n",
    "\n",
    "# Daten und Labels laden\n",
    "def load_data_and_labels(base_path):\n",
    "    emotions = {'Angst': 0, 'Ekel': 1, 'Trauer': 2, 'Freude': 3}\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    for emotion, label in emotions.items():\n",
    "        emotion_path = os.path.join(base_path, emotion)\n",
    "        for filename in os.listdir(emotion_path):\n",
    "            if filename.endswith(\".wav\"):\n",
    "                file_path = os.path.join(emotion_path, filename)\n",
    "                features = extract_audio_features(file_path)\n",
    "                features_list.append(features)\n",
    "                labels_list.append(label)\n",
    "    return np.array(features_list), np.array(labels_list)\n",
    "\n",
    "# CNN Modelldefinition mit L2-Regularisierung und erweiterten Schichten\n",
    "def build_model(input_shape, number_of_classes):\n",
    "    model = Sequential([\n",
    "        Conv1D(256, 5, input_shape=input_shape, padding='same', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(128, 5, padding='same', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Dropout(0.2),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(128, 5, padding='same', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.2),\n",
    "        Dense(number_of_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Hauptskript\n",
    "base_path = r'C:\\Users\\zastr\\Desktop\\Thesis\\Data\\Audio\\Emo_DB'\n",
    "features, labels = load_data_and_labels(base_path)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.67, random_state=42)\n",
    "\n",
    "model = build_model((193, 1), len(np.unique(labels)))\n",
    "\n",
    "# Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Modelltraining mit Early Stopping und Learning Rate Reduction\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=32, callbacks=[reduce_lr, early_stopping])\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}, Test loss: {test_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 80ms/step - loss: 2.3629 - accuracy: 0.3064 - val_loss: 1.9595 - val_accuracy: 0.4000 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.9628 - accuracy: 0.3931 - val_loss: 2.0610 - val_accuracy: 0.3200 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7960 - accuracy: 0.4509 - val_loss: 2.0086 - val_accuracy: 0.4800 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.7019 - accuracy: 0.5434 - val_loss: 2.0632 - val_accuracy: 0.4800 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.6833 - accuracy: 0.4798 - val_loss: 2.0784 - val_accuracy: 0.4800 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.5389 - accuracy: 0.5665 - val_loss: 2.0711 - val_accuracy: 0.4400 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4926 - accuracy: 0.6127 - val_loss: 2.0373 - val_accuracy: 0.4400 - lr: 2.0000e-05\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4594 - accuracy: 0.6358 - val_loss: 1.9775 - val_accuracy: 0.4400 - lr: 2.0000e-05\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5054 - accuracy: 0.6127 - val_loss: 1.9283 - val_accuracy: 0.4400 - lr: 2.0000e-05\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5306 - accuracy: 0.5896 - val_loss: 1.8890 - val_accuracy: 0.4800 - lr: 2.0000e-05\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4492 - accuracy: 0.6532 - val_loss: 1.8294 - val_accuracy: 0.4800 - lr: 2.0000e-05\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4713 - accuracy: 0.6127 - val_loss: 1.7702 - val_accuracy: 0.4800 - lr: 2.0000e-05\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4560 - accuracy: 0.6416 - val_loss: 1.7376 - val_accuracy: 0.4800 - lr: 2.0000e-05\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4917 - accuracy: 0.6590 - val_loss: 1.7226 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4417 - accuracy: 0.6416 - val_loss: 1.6979 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4341 - accuracy: 0.6127 - val_loss: 1.6804 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4560 - accuracy: 0.6763 - val_loss: 1.6739 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.3694 - accuracy: 0.6647 - val_loss: 1.6573 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4508 - accuracy: 0.6416 - val_loss: 1.6326 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4025 - accuracy: 0.6821 - val_loss: 1.6022 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2666 - accuracy: 0.7399 - val_loss: 1.5800 - val_accuracy: 0.5200 - lr: 2.0000e-05\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.3929 - accuracy: 0.6994 - val_loss: 1.5656 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4343 - accuracy: 0.6127 - val_loss: 1.5396 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.3014 - accuracy: 0.6936 - val_loss: 1.5255 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2943 - accuracy: 0.7283 - val_loss: 1.5302 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.3632 - accuracy: 0.6705 - val_loss: 1.5234 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3261 - accuracy: 0.6936 - val_loss: 1.5112 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3534 - accuracy: 0.6879 - val_loss: 1.4867 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2920 - accuracy: 0.7283 - val_loss: 1.4690 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3091 - accuracy: 0.7225 - val_loss: 1.4582 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.3068 - accuracy: 0.7110 - val_loss: 1.4356 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3214 - accuracy: 0.6763 - val_loss: 1.4269 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3081 - accuracy: 0.6647 - val_loss: 1.4268 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3052 - accuracy: 0.7110 - val_loss: 1.4307 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2938 - accuracy: 0.6936 - val_loss: 1.4225 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2703 - accuracy: 0.7225 - val_loss: 1.4029 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3130 - accuracy: 0.6821 - val_loss: 1.3877 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2787 - accuracy: 0.7052 - val_loss: 1.3735 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2275 - accuracy: 0.7283 - val_loss: 1.3609 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2793 - accuracy: 0.7168 - val_loss: 1.3543 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2107 - accuracy: 0.7457 - val_loss: 1.3512 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2542 - accuracy: 0.6879 - val_loss: 1.3514 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2649 - accuracy: 0.6936 - val_loss: 1.3527 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2917 - accuracy: 0.6763 - val_loss: 1.3465 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1812 - accuracy: 0.7572 - val_loss: 1.3378 - val_accuracy: 0.6400 - lr: 2.0000e-05\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2581 - accuracy: 0.7341 - val_loss: 1.3274 - val_accuracy: 0.6800 - lr: 2.0000e-05\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2082 - accuracy: 0.7514 - val_loss: 1.3202 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1752 - accuracy: 0.7572 - val_loss: 1.3149 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2186 - accuracy: 0.6994 - val_loss: 1.3104 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1784 - accuracy: 0.7630 - val_loss: 1.3125 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2238 - accuracy: 0.7457 - val_loss: 1.3116 - val_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1844 - accuracy: 0.7977 - val_loss: 1.3125 - val_accuracy: 0.6400 - lr: 2.0000e-05\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1925 - accuracy: 0.7572 - val_loss: 1.3124 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2037 - accuracy: 0.7341 - val_loss: 1.3052 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1235 - accuracy: 0.7977 - val_loss: 1.2970 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1671 - accuracy: 0.7457 - val_loss: 1.2899 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1271 - accuracy: 0.7341 - val_loss: 1.2803 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1123 - accuracy: 0.7919 - val_loss: 1.2767 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2003 - accuracy: 0.7572 - val_loss: 1.2692 - val_accuracy: 0.6000 - lr: 2.0000e-05\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1620 - accuracy: 0.7688 - val_loss: 1.2535 - val_accuracy: 0.6800 - lr: 2.0000e-05\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1264 - accuracy: 0.7457 - val_loss: 1.2451 - val_accuracy: 0.6800 - lr: 2.0000e-05\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2123 - accuracy: 0.7572 - val_loss: 1.2403 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1311 - accuracy: 0.7803 - val_loss: 1.2333 - val_accuracy: 0.6400 - lr: 2.0000e-05\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1461 - accuracy: 0.7572 - val_loss: 1.2317 - val_accuracy: 0.6800 - lr: 2.0000e-05\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1127 - accuracy: 0.7688 - val_loss: 1.2297 - val_accuracy: 0.6400 - lr: 2.0000e-05\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0675 - accuracy: 0.8035 - val_loss: 1.2277 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1304 - accuracy: 0.7861 - val_loss: 1.2260 - val_accuracy: 0.6800 - lr: 2.0000e-05\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0702 - accuracy: 0.7977 - val_loss: 1.2269 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0302 - accuracy: 0.8035 - val_loss: 1.2205 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0699 - accuracy: 0.7977 - val_loss: 1.2175 - val_accuracy: 0.6400 - lr: 2.0000e-05\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0520 - accuracy: 0.7977 - val_loss: 1.2126 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0908 - accuracy: 0.7746 - val_loss: 1.2131 - val_accuracy: 0.7600 - lr: 2.0000e-05\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0666 - accuracy: 0.7803 - val_loss: 1.2092 - val_accuracy: 0.7600 - lr: 2.0000e-05\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1234 - accuracy: 0.7457 - val_loss: 1.2037 - val_accuracy: 0.7600 - lr: 2.0000e-05\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1042 - accuracy: 0.7688 - val_loss: 1.1944 - val_accuracy: 0.7600 - lr: 2.0000e-05\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1008 - accuracy: 0.8150 - val_loss: 1.1898 - val_accuracy: 0.7600 - lr: 2.0000e-05\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0436 - accuracy: 0.7919 - val_loss: 1.1865 - val_accuracy: 0.6800 - lr: 2.0000e-05\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9865 - accuracy: 0.8439 - val_loss: 1.1837 - val_accuracy: 0.7600 - lr: 2.0000e-05\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0327 - accuracy: 0.8092 - val_loss: 1.1856 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1142 - accuracy: 0.7803 - val_loss: 1.1846 - val_accuracy: 0.6800 - lr: 2.0000e-05\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0548 - accuracy: 0.8266 - val_loss: 1.1699 - val_accuracy: 0.7600 - lr: 2.0000e-05\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0474 - accuracy: 0.8092 - val_loss: 1.1640 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0852 - accuracy: 0.8035 - val_loss: 1.1621 - val_accuracy: 0.7600 - lr: 2.0000e-05\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0305 - accuracy: 0.8208 - val_loss: 1.1688 - val_accuracy: 0.7600 - lr: 2.0000e-05\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1200 - accuracy: 0.7572 - val_loss: 1.1713 - val_accuracy: 0.7600 - lr: 2.0000e-05\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0008 - accuracy: 0.8035 - val_loss: 1.1714 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9726 - accuracy: 0.8208 - val_loss: 1.1685 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0017 - accuracy: 0.7919 - val_loss: 1.1507 - val_accuracy: 0.7600 - lr: 2.0000e-05\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0445 - accuracy: 0.7861 - val_loss: 1.1436 - val_accuracy: 0.7600 - lr: 2.0000e-05\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9830 - accuracy: 0.8266 - val_loss: 1.1407 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9577 - accuracy: 0.8208 - val_loss: 1.1369 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0078 - accuracy: 0.8208 - val_loss: 1.1312 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9880 - accuracy: 0.7977 - val_loss: 1.1179 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0048 - accuracy: 0.8208 - val_loss: 1.1178 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0434 - accuracy: 0.7861 - val_loss: 1.1201 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9731 - accuracy: 0.8266 - val_loss: 1.1207 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0081 - accuracy: 0.8266 - val_loss: 1.1296 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9553 - accuracy: 0.8324 - val_loss: 1.1185 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9808 - accuracy: 0.8092 - val_loss: 1.1148 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9378 - accuracy: 0.8786 - val_loss: 1.1188 - val_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9684 - accuracy: 0.8200\n",
      "Test accuracy: 0.8199999928474426, Test loss: 0.9683815836906433\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, BatchNormalization, MaxPooling1D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Funktion zur Extraktion der Audio-Features\n",
    "def extract_audio_features(file_path, n_fft=512):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    chromagram = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "    features = np.hstack((np.mean(mfccs, axis=1), \n",
    "                          np.mean(librosa.power_to_db(mel_spectrogram), axis=1),\n",
    "                          np.mean(chromagram, axis=1),\n",
    "                          np.mean(spectral_contrast, axis=1),\n",
    "                          np.mean(tonnetz, axis=1)))\n",
    "    if len(features) > 193:\n",
    "        features = features[:193]\n",
    "    elif len(features) < 193:\n",
    "        features = np.pad(features, (0, 193 - len(features)), 'constant')\n",
    "    return features\n",
    "\n",
    "# Daten und Labels laden\n",
    "def load_data_and_labels(base_path):\n",
    "    emotions = {'Angst': 0, 'Ekel': 1, 'Trauer': 2, 'Freude': 3}\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    for emotion, label in emotions.items():\n",
    "        emotion_path = os.path.join(base_path, emotion)\n",
    "        for filename in os.listdir(emotion_path):\n",
    "            if filename.endswith(\".wav\"):\n",
    "                file_path = os.path.join(emotion_path, filename)\n",
    "                features = extract_audio_features(file_path)\n",
    "                features_list.append(features)\n",
    "                labels_list.append(label)\n",
    "    return np.array(features_list), np.array(labels_list)\n",
    "\n",
    "# CNN Modelldefinition mit L2-Regularisierung und erweiterten Schichten\n",
    "def build_model(input_shape, number_of_classes):\n",
    "    model = Sequential([\n",
    "        Conv1D(256, 5, input_shape=input_shape, padding='same', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(128, 5, padding='same', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Dropout(0.2),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(128, 5, padding='same', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Dropout(0.3),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.4),\n",
    "        Dense(number_of_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Hauptskript\n",
    "base_path = r'C:\\Users\\zastr\\Desktop\\Thesis\\Data\\Audio\\Emo_DB'\n",
    "features, labels = load_data_and_labels(base_path)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=(2/3), random_state=42)\n",
    "\n",
    "model = build_model((193, 1), len(np.unique(labels)))\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[reduce_lr])\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}, Test loss: {test_loss}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
