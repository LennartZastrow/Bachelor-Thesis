{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models für Mimikanalyse : ResNet50 , Resnet101,  VGG16, VGG19, InceptionV3, DenseNet 169 und EfficientNetB7 mit Dataaugmenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow-Version: 2.10.1\n",
      "Verfügbare Geräte: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Ist eine GPU verfügbar: True\n",
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow-Version:\", tf.__version__)\n",
    "\n",
    "# Liste der verfügbaren Geräte abrufen\n",
    "available_devices = tf.config.list_physical_devices()\n",
    "print(\"Verfügbare Geräte:\", available_devices)\n",
    "\n",
    "# Überprüfen, ob eine GPU verfügbar ist\n",
    "is_gpu_available = tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)\n",
    "print(\"Ist eine GPU verfügbar:\", is_gpu_available)\n",
    "\n",
    "# Spezifisch nach GPUs suchen\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs:\", gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard Callback einrichten\n",
    "import datetime\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2508 files belonging to 4 classes.\n",
      "Using 2007 files for training.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "Found 2508 files belonging to 4 classes.\n",
      "Using 501 files for validation.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "Epoch 1/9\n",
      "63/63 [==============================] - 30s 435ms/step - loss: 1.5086 - accuracy: 0.5386 - val_loss: 0.7096 - val_accuracy: 0.7206\n",
      "Epoch 2/9\n",
      "63/63 [==============================] - 21s 325ms/step - loss: 0.6216 - accuracy: 0.7673 - val_loss: 0.4523 - val_accuracy: 0.8423\n",
      "Epoch 3/9\n",
      "63/63 [==============================] - 13s 195ms/step - loss: 0.4767 - accuracy: 0.8201 - val_loss: 0.4029 - val_accuracy: 0.8603\n",
      "Epoch 4/9\n",
      "63/63 [==============================] - 13s 196ms/step - loss: 0.3973 - accuracy: 0.8475 - val_loss: 0.3964 - val_accuracy: 0.8363\n",
      "Epoch 5/9\n",
      "63/63 [==============================] - 13s 198ms/step - loss: 0.3561 - accuracy: 0.8665 - val_loss: 0.3048 - val_accuracy: 0.8802\n",
      "Epoch 6/9\n",
      "63/63 [==============================] - 13s 198ms/step - loss: 0.3230 - accuracy: 0.8705 - val_loss: 0.2463 - val_accuracy: 0.9182\n",
      "Epoch 7/9\n",
      "63/63 [==============================] - 13s 200ms/step - loss: 0.2722 - accuracy: 0.8969 - val_loss: 0.2466 - val_accuracy: 0.9042\n",
      "Epoch 8/9\n",
      "63/63 [==============================] - 12s 192ms/step - loss: 0.2699 - accuracy: 0.8934 - val_loss: 0.2849 - val_accuracy: 0.9002\n",
      "Epoch 9/9\n",
      "63/63 [==============================] - 17s 266ms/step - loss: 0.2560 - accuracy: 0.8989 - val_loss: 0.2382 - val_accuracy: 0.9142\n",
      "Found 626 files belonging to 4 classes.\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 1.6392 - accuracy: 0.4521\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import datetime\n",
    "\n",
    "# Betitelung für Tensorboard\n",
    "experiment_name = \"ResNet50_Dataaug\"\n",
    "\n",
    "# Data Augmentation Layer hinzufügen\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),  # Rotation um bis zu 20%\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),  # Horizontaler und vertikaler Flip\n",
    "    tf.keras.layers.experimental.preprocessing.RandomContrast(0.1),  # Zufällige Kontrastanpassung\n",
    "])\n",
    "\n",
    "# Funktion zur Vorbereitung und Augmentation der Bilder\n",
    "def preprocess_and_augment_dataset(ds):\n",
    "    # Zuerst Data Augmentation anwenden\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "    # Dann die spezifische Vorverarbeitung für ResNet50 anwenden\n",
    "    return ds.map(lambda x, y: (preprocess_input(x), y))\n",
    "\n",
    "# Funktion zur Vorbereitung der Testdaten\n",
    "def preprocess_dataset(ds):\n",
    "    return ds.map(lambda x, y: (preprocess_input(x), y))\n",
    "\n",
    "# Trainingsdaten laden und vorbereiten\n",
    "train_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "\n",
    "# Anwendung der Vorverarbeitung und Augmentation auf Trainingsdaten\n",
    "train_ds = preprocess_and_augment_dataset(train_ds)\n",
    "\n",
    "# Validierungsdaten laden und vorbereiten\n",
    "val_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "\n",
    "# Anwendung der Vorverarbeitung (ohne Augmentation) auf Validierungsdaten\n",
    "val_ds = preprocess_and_augment_dataset(val_ds)  \n",
    "\n",
    "# Vortrainiertes Modell laden\n",
    "base_model = ResNet50(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  # Einfrieren der Basis-Schichten\n",
    "\n",
    "# Modell anpassen\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)  # Dropout zur Regulierung von Overfitting\n",
    "outputs = Dense(4, activation='softmax')(x)  # 4 Klassen für die Emotionen\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Modell kompilieren und trainieren\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Setze den Pfad für die TensorBoard Logs\n",
    "log_dir = \"logs/fit/\" + experiment_name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, update_freq=\"epoch\")\n",
    "\n",
    "model.fit(\n",
    "    train_ds, \n",
    "    validation_data=val_ds, \n",
    "    epochs=9, \n",
    "    callbacks=[tensorboard_callback]  # TensorBoard Callback hinzufügen\n",
    ")\n",
    "\n",
    "# Modell mit Testdaten testen\n",
    "test_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions_Test\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "\n",
    "test_ds = preprocess_dataset(test_ds)  \n",
    "\n",
    "# Modell evaluieren\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "\n",
    "# Pfad für Test-Logs setzen\n",
    "test_log_dir = \"logs/fit/\" + experiment_name + \"_test_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Summary Writer für Testdaten erstellen\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "\n",
    "# Testmetriken in TensorBoard loggen\n",
    "with test_summary_writer.as_default():\n",
    "    tf.summary.scalar('test_loss', test_loss, step=0)\n",
    "    tf.summary.scalar('test_accuracy', test_accuracy, step=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2508 files belonging to 4 classes.\n",
      "Using 2007 files for training.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "Found 2508 files belonging to 4 classes.\n",
      "Using 501 files for validation.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "Epoch 1/9\n",
      "63/63 [==============================] - 24s 319ms/step - loss: 1.0965 - accuracy: 0.6378 - val_loss: 0.8675 - val_accuracy: 0.6307\n",
      "Epoch 2/9\n",
      "63/63 [==============================] - 21s 325ms/step - loss: 0.5178 - accuracy: 0.7912 - val_loss: 0.8431 - val_accuracy: 0.7046\n",
      "Epoch 3/9\n",
      "63/63 [==============================] - 20s 315ms/step - loss: 0.4192 - accuracy: 0.8396 - val_loss: 0.9053 - val_accuracy: 0.6447\n",
      "Epoch 4/9\n",
      "63/63 [==============================] - 19s 300ms/step - loss: 0.3325 - accuracy: 0.8744 - val_loss: 0.7333 - val_accuracy: 0.7006\n",
      "Epoch 5/9\n",
      "63/63 [==============================] - 21s 320ms/step - loss: 0.3085 - accuracy: 0.8809 - val_loss: 0.7338 - val_accuracy: 0.7066\n",
      "Epoch 6/9\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 0.3455 - accuracy: 0.8620 - val_loss: 0.8798 - val_accuracy: 0.6387\n",
      "Epoch 7/9\n",
      "63/63 [==============================] - 22s 337ms/step - loss: 0.2455 - accuracy: 0.9088 - val_loss: 0.8546 - val_accuracy: 0.6507\n",
      "Epoch 8/9\n",
      "63/63 [==============================] - 18s 281ms/step - loss: 0.2492 - accuracy: 0.9018 - val_loss: 0.7990 - val_accuracy: 0.6587\n",
      "Epoch 9/9\n",
      "63/63 [==============================] - 18s 287ms/step - loss: 0.2083 - accuracy: 0.9173 - val_loss: 0.7021 - val_accuracy: 0.7086\n",
      "Found 626 files belonging to 4 classes.\n",
      "20/20 [==============================] - 3s 101ms/step - loss: 0.8656 - accuracy: 0.6693\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# Betitelung für Tensorboard\n",
    "experiment_name = \"ResNet101_Dataaug\"\n",
    "\n",
    "# Data Augmentation Layer hinzufügen\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),  # Rotation um bis zu 20%\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),  # Horizontaler und vertikaler Flip\n",
    "    tf.keras.layers.experimental.preprocessing.RandomContrast(0.1),  # Zufällige Kontrastanpassung\n",
    "])\n",
    "\n",
    "# Funktion zur Vorbereitung und Augmentation der Bilder\n",
    "def preprocess_and_augment_dataset(ds):\n",
    "    # Zuerst Data Augmentation anwenden\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "    # Dann die spezifische Vorverarbeitung für ResNet50 anwenden\n",
    "    return ds.map(lambda x, y: (preprocess_input(x), y))\n",
    "\n",
    "# Funktion zur Vorbereitung der Testdaten\n",
    "def preprocess_dataset(ds):\n",
    "    return ds.map(lambda x, y: (preprocess_input(x), y))\n",
    "    \n",
    "# Trainingsdaten laden und vorbereiten\n",
    "train_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "\n",
    "# Anwendung der Vorverarbeitung und Augmentation auf Trainingsdaten\n",
    "train_ds = preprocess_and_augment_dataset(train_ds)\n",
    "\n",
    "# Validierungsdaten laden und vorbereiten\n",
    "val_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "\n",
    "# Anwendung der Vorverarbeitung (ohne Augmentation) auf Validierungsdaten\n",
    "val_ds = preprocess_and_augment_dataset(val_ds) \n",
    "\n",
    "# Vortrainiertes Modell laden\n",
    "base_model = ResNet101(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  # Einfrieren der Basis-Schichten\n",
    "\n",
    "# Modell anpassen\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.2)(x) # Dropout zur Regulierung von Overfitting\n",
    "outputs = Dense(4, activation='softmax')(x)  # 4 Klassen für die Emotionen\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Modell kompilieren und trainieren\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Setze den Pfad für die TensorBoard Logs\n",
    "log_dir = \"logs/fit/\" + experiment_name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, update_freq=\"epoch\")\n",
    "\n",
    "model.fit(\n",
    "    train_ds, \n",
    "    validation_data=val_ds, \n",
    "    epochs=9, \n",
    "    callbacks=[tensorboard_callback]  # TensorBoard Callback hinzufügen\n",
    ")\n",
    "\n",
    "# Modell mit Testdaten testen\n",
    "test_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions_Test\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "test_ds = preprocess_dataset(test_ds)\n",
    "\n",
    "# Modell evaluieren\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "\n",
    "# Pfad für Test-Logs setzen\n",
    "test_log_dir = \"logs/fit/\" + experiment_name + \"_test_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Summary Writer für Testdaten erstellen\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "\n",
    "# Testmetriken in TensorBoard loggen\n",
    "with test_summary_writer.as_default():\n",
    "    tf.summary.scalar('test_loss', test_loss, step=0)\n",
    "    tf.summary.scalar('test_accuracy', test_accuracy, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2508 files belonging to 4 classes.\n",
      "Using 2007 files for training.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "Found 2508 files belonging to 4 classes.\n",
      "Using 501 files for validation.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "Epoch 1/9\n",
      "63/63 [==============================] - 32s 372ms/step - loss: 1.3330 - accuracy: 0.6034 - val_loss: 1.1860 - val_accuracy: 0.5689\n",
      "Epoch 2/9\n",
      "63/63 [==============================] - 17s 260ms/step - loss: 0.4712 - accuracy: 0.8166 - val_loss: 0.8247 - val_accuracy: 0.6747\n",
      "Epoch 3/9\n",
      "63/63 [==============================] - 17s 275ms/step - loss: 0.3504 - accuracy: 0.8655 - val_loss: 0.8557 - val_accuracy: 0.6906\n",
      "Epoch 4/9\n",
      "63/63 [==============================] - 18s 275ms/step - loss: 0.3099 - accuracy: 0.8844 - val_loss: 0.7495 - val_accuracy: 0.7186\n",
      "Epoch 5/9\n",
      "63/63 [==============================] - 17s 260ms/step - loss: 0.2575 - accuracy: 0.9033 - val_loss: 0.8939 - val_accuracy: 0.7186\n",
      "Epoch 6/9\n",
      "63/63 [==============================] - 17s 262ms/step - loss: 0.2243 - accuracy: 0.9153 - val_loss: 0.8539 - val_accuracy: 0.7146\n",
      "Epoch 7/9\n",
      "63/63 [==============================] - 17s 262ms/step - loss: 0.2169 - accuracy: 0.9153 - val_loss: 0.8187 - val_accuracy: 0.7265\n",
      "Epoch 8/9\n",
      "63/63 [==============================] - 16s 258ms/step - loss: 0.2240 - accuracy: 0.9203 - val_loss: 0.8268 - val_accuracy: 0.7086\n",
      "Epoch 9/9\n",
      "63/63 [==============================] - 17s 259ms/step - loss: 0.1584 - accuracy: 0.9452 - val_loss: 1.0382 - val_accuracy: 0.7046\n",
      "Found 626 files belonging to 4 classes.\n",
      "20/20 [==============================] - 6s 274ms/step - loss: 0.1819 - accuracy: 0.9377\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Betitelung für Tensorboard\n",
    "experiment_name = \"VGG16_Dataaug\"\n",
    "\n",
    "# Data Augmentation Layer hinzufügen\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),  # Rotation um bis zu 20%\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),  # Horizontaler und vertikaler Flip\n",
    "    tf.keras.layers.experimental.preprocessing.RandomContrast(0.1),  # Zufällige Kontrastanpassung\n",
    "])\n",
    "\n",
    "# Funktion zur Vorbereitung und Augmentation der Bilder\n",
    "def preprocess_and_augment_dataset(ds):\n",
    "    # Zuerst Data Augmentation anwenden\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "    # Dann die spezifische Vorverarbeitung für ResNet50 anwenden\n",
    "    return ds.map(lambda x, y: (preprocess_input(x), y))\n",
    "\n",
    "# Funktion zur Vorbereitung der Testdaten\n",
    "def preprocess_dataset(ds):\n",
    "    return ds.map(lambda x, y: (preprocess_input(x), y))\n",
    "    \n",
    "# Trainingsdaten laden und vorbereiten\n",
    "train_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "\n",
    "# Anwendung der Vorverarbeitung und Augmentation auf Trainingsdaten\n",
    "train_ds = preprocess_and_augment_dataset(train_ds)\n",
    "\n",
    "# Validierungsdaten laden und vorbereiten\n",
    "val_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "\n",
    "# Anwendung der Vorverarbeitung (ohne Augmentation) auf Validierungsdaten\n",
    "val_ds = preprocess_and_augment_dataset(val_ds) \n",
    "\n",
    "# Vortrainiertes Modell laden\n",
    "base_model = VGG16(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  # Einfrieren der Basis-Schichten\n",
    "\n",
    "# Modell anpassen\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.2)(x) # Dropout zur Regulierung von Overfitting\n",
    "outputs = Dense(4, activation='softmax')(x)  # 4 Klassen für die Emotionen\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Modell kompilieren und trainieren\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Setze den Pfad für die TensorBoard Logs\n",
    "log_dir = \"logs/fit/\" + experiment_name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, update_freq=\"epoch\")\n",
    "\n",
    "model.fit(\n",
    "    train_ds, \n",
    "    validation_data=val_ds, \n",
    "    epochs=9, \n",
    "    callbacks=[tensorboard_callback]  # TensorBoard Callback hinzufügen\n",
    ")\n",
    "\n",
    "# Modell mit Testdaten testen\n",
    "test_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions_Test\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "test_ds = preprocess_dataset(test_ds)\n",
    "\n",
    "# Modell evaluieren\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "\n",
    "# Pfad für Test-Logs setzen\n",
    "test_log_dir = \"logs/fit/\" + experiment_name + \"_test_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Summary Writer für Testdaten erstellen\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "\n",
    "# Testmetriken in TensorBoard loggen\n",
    "with test_summary_writer.as_default():\n",
    "    tf.summary.scalar('test_loss', test_loss, step=0)\n",
    "    tf.summary.scalar('test_accuracy', test_accuracy, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2508 files belonging to 4 classes.\n",
      "Using 2007 files for training.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "Found 2508 files belonging to 4 classes.\n",
      "Using 501 files for validation.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "Epoch 1/9\n",
      "63/63 [==============================] - 25s 335ms/step - loss: 1.2046 - accuracy: 0.6482 - val_loss: 0.9105 - val_accuracy: 0.6287\n",
      "Epoch 2/9\n",
      "63/63 [==============================] - 19s 294ms/step - loss: 0.4744 - accuracy: 0.8221 - val_loss: 0.9697 - val_accuracy: 0.6208\n",
      "Epoch 3/9\n",
      "63/63 [==============================] - 19s 299ms/step - loss: 0.3193 - accuracy: 0.8829 - val_loss: 0.8445 - val_accuracy: 0.6687\n",
      "Epoch 4/9\n",
      "63/63 [==============================] - 19s 290ms/step - loss: 0.2952 - accuracy: 0.8879 - val_loss: 0.9449 - val_accuracy: 0.6507\n",
      "Epoch 5/9\n",
      "63/63 [==============================] - 16s 249ms/step - loss: 0.2689 - accuracy: 0.8974 - val_loss: 0.9809 - val_accuracy: 0.5908\n",
      "Epoch 6/9\n",
      "63/63 [==============================] - 16s 251ms/step - loss: 0.2276 - accuracy: 0.9148 - val_loss: 0.9970 - val_accuracy: 0.5749\n",
      "Epoch 7/9\n",
      "63/63 [==============================] - 16s 245ms/step - loss: 0.1893 - accuracy: 0.9332 - val_loss: 0.9805 - val_accuracy: 0.6148\n",
      "Epoch 8/9\n",
      "63/63 [==============================] - 16s 249ms/step - loss: 0.1817 - accuracy: 0.9327 - val_loss: 0.8285 - val_accuracy: 0.6906\n",
      "Epoch 9/9\n",
      "63/63 [==============================] - 21s 324ms/step - loss: 0.1353 - accuracy: 0.9512 - val_loss: 0.9059 - val_accuracy: 0.6647\n",
      "Found 626 files belonging to 4 classes.\n",
      "20/20 [==============================] - 4s 183ms/step - loss: 1.6396 - accuracy: 0.4281\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "# Betitelung für Tensorboard\n",
    "experiment_name = \"VGG19_Dataaug\"\n",
    "\n",
    "# Data Augmentation Layer hinzufügen\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),  # Rotation um bis zu 20%\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),  # Horizontaler und vertikaler Flip\n",
    "    tf.keras.layers.experimental.preprocessing.RandomContrast(0.1),  # Zufällige Kontrastanpassung\n",
    "])\n",
    "\n",
    "# Funktion zur Vorbereitung und Augmentation der Bilder\n",
    "def preprocess_and_augment_dataset(ds):\n",
    "    # Zuerst Data Augmentation anwenden\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "    # Dann die spezifische Vorverarbeitung für ResNet50 anwenden\n",
    "    return ds.map(lambda x, y: (preprocess_input(x), y))\n",
    "\n",
    "# Funktion zur Vorbereitung der Testdaten\n",
    "def preprocess_dataset(ds):\n",
    "    return ds.map(lambda x, y: (preprocess_input(x), y))\n",
    "    \n",
    "# Trainingsdaten laden und vorbereiten\n",
    "train_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "\n",
    "# Anwendung der Vorverarbeitung und Augmentation auf Trainingsdaten\n",
    "train_ds = preprocess_and_augment_dataset(train_ds)\n",
    "\n",
    "# Validierungsdaten laden und vorbereiten\n",
    "val_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "\n",
    "# Anwendung der Vorverarbeitung (ohne Augmentation) auf Validierungsdaten\n",
    "val_ds = preprocess_and_augment_dataset(val_ds) \n",
    "\n",
    "# Vortrainiertes Modell laden\n",
    "base_model = VGG19(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  # Einfrieren der Basis-Schichten\n",
    "\n",
    "# Modell anpassen\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.2)(x) # Dropout zur Regulierung von Overfitting\n",
    "outputs = Dense(4, activation='softmax')(x)  # 4 Klassen für die Emotionen\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Modell kompilieren und trainieren\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Setze den Pfad für die TensorBoard Logs\n",
    "log_dir = \"logs/fit/\" + experiment_name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, update_freq=\"epoch\")\n",
    "\n",
    "model.fit(\n",
    "    train_ds, \n",
    "    validation_data=val_ds, \n",
    "    epochs=9, \n",
    "    callbacks=[tensorboard_callback]  # TensorBoard Callback hinzufügen\n",
    ")\n",
    "\n",
    "# Modell mit Testdaten testen\n",
    "test_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions_Test\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "test_ds = preprocess_dataset(test_ds)\n",
    "\n",
    "# Modell evaluieren\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "\n",
    "# Pfad für Test-Logs setzen\n",
    "test_log_dir = \"logs/fit/\" + experiment_name + \"_test_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Summary Writer für Testdaten erstellen\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "\n",
    "# Testmetriken in TensorBoard loggen\n",
    "with test_summary_writer.as_default():\n",
    "    tf.summary.scalar('test_loss', test_loss, step=0)\n",
    "    tf.summary.scalar('test_accuracy', test_accuracy, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### InceptionNetV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2508 files belonging to 4 classes.\n",
      "Using 2007 files for training.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "Found 2508 files belonging to 4 classes.\n",
      "Using 501 files for validation.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "Epoch 1/9\n",
      "63/63 [==============================] - 115s 2s/step - loss: 1.1874 - accuracy: 0.5650 - val_loss: 1.3332 - val_accuracy: 0.5090\n",
      "Epoch 2/9\n",
      "63/63 [==============================] - 21s 327ms/step - loss: 0.7090 - accuracy: 0.7135 - val_loss: 1.1326 - val_accuracy: 0.5589\n",
      "Epoch 3/9\n",
      "63/63 [==============================] - 20s 318ms/step - loss: 0.5671 - accuracy: 0.7698 - val_loss: 1.0900 - val_accuracy: 0.5768\n",
      "Epoch 4/9\n",
      "63/63 [==============================] - 23s 361ms/step - loss: 0.4758 - accuracy: 0.8191 - val_loss: 1.2464 - val_accuracy: 0.5549\n",
      "Epoch 5/9\n",
      "63/63 [==============================] - 22s 349ms/step - loss: 0.4082 - accuracy: 0.8376 - val_loss: 1.4000 - val_accuracy: 0.5469\n",
      "Epoch 6/9\n",
      "63/63 [==============================] - 22s 352ms/step - loss: 0.4286 - accuracy: 0.8306 - val_loss: 1.5012 - val_accuracy: 0.5349\n",
      "Epoch 7/9\n",
      "63/63 [==============================] - 22s 343ms/step - loss: 0.3739 - accuracy: 0.8555 - val_loss: 1.0651 - val_accuracy: 0.6128\n",
      "Epoch 8/9\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 0.4227 - accuracy: 0.8306 - val_loss: 1.1004 - val_accuracy: 0.6407\n",
      "Epoch 9/9\n",
      "63/63 [==============================] - 22s 340ms/step - loss: 0.3217 - accuracy: 0.8769 - val_loss: 0.9042 - val_accuracy: 0.6527\n",
      "Found 626 files belonging to 4 classes.\n",
      "20/20 [==============================] - 4s 152ms/step - loss: 1.7537 - accuracy: 0.4265\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "# Betitelung für Tensorboard\n",
    "experiment_name = \"InceptionV3_Dataaug\"\n",
    "\n",
    "# Data Augmentation Layer hinzufügen\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),  # Rotation um bis zu 20%\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),  # Horizontaler und vertikaler Flip\n",
    "    tf.keras.layers.experimental.preprocessing.RandomContrast(0.1),  # Zufällige Kontrastanpassung\n",
    "])\n",
    "\n",
    "# Funktion zur Vorbereitung und Augmentation der Bilder\n",
    "def preprocess_and_augment_dataset(ds):\n",
    "    # Zuerst Data Augmentation anwenden\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "    # Dann die spezifische Vorverarbeitung für ResNet50 anwenden\n",
    "    return ds.map(lambda x, y: (preprocess_input(x), y))\n",
    "\n",
    "# Funktion zur Vorbereitung der Testdaten\n",
    "def preprocess_dataset(ds):\n",
    "    return ds.map(lambda x, y: (preprocess_input(x), y))\n",
    "\n",
    "# Trainingsdaten laden und vorbereiten\n",
    "train_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(299, 299),\n",
    "    batch_size=32)\n",
    "\n",
    "# Anwendung der Vorverarbeitung und Augmentation auf Trainingsdaten\n",
    "train_ds = preprocess_and_augment_dataset(train_ds)\n",
    "\n",
    "# Validierungsdaten laden und vorbereiten\n",
    "val_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(299, 299),\n",
    "    batch_size=32)\n",
    "\n",
    "# Anwendung der Vorverarbeitung (ohne Augmentation) auf Validierungsdaten\n",
    "val_ds = preprocess_and_augment_dataset(val_ds) \n",
    "\n",
    "# Vortrainiertes Modell laden\n",
    "base_model = InceptionV3(input_shape=(299, 299, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  # Einfrieren der Basis-Schichten\n",
    "\n",
    "\n",
    "# Modell anpassen\n",
    "inputs = tf.keras.Input(shape=(299, 299, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "outputs = Dense(4, activation='softmax')(x)  # 4 Klassen für Emotionen\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Modell kompilieren und trainieren\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Setze den Pfad für die TensorBoard Logs\n",
    "log_dir = \"logs/fit/\" + experiment_name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, update_freq=\"epoch\")\n",
    "\n",
    "model.fit(\n",
    "    train_ds, \n",
    "    validation_data=val_ds, \n",
    "    epochs=9, \n",
    "    callbacks=[tensorboard_callback]  # TensorBoard Callback hinzufügen\n",
    ")\n",
    "\n",
    "# Modell mit Testdaten testen\n",
    "test_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions_Test\",\n",
    "    image_size=(299, 299),\n",
    "    batch_size=32)\n",
    "test_ds = preprocess_dataset(test_ds)\n",
    "\n",
    "# Modell evaluieren\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "\n",
    "# Pfad für Test-Logs setzen\n",
    "test_log_dir = \"logs/fit/\" + experiment_name + \"_test_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Summary Writer für Testdaten erstellen\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "\n",
    "# Testmetriken in TensorBoard loggen\n",
    "with test_summary_writer.as_default():\n",
    "    tf.summary.scalar('test_loss', test_loss, step=0)\n",
    "    tf.summary.scalar('test_accuracy', test_accuracy, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DenseNet161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2508 files belonging to 4 classes.\n",
      "Using 2007 files for training.\n",
      "Found 2508 files belonging to 4 classes.\n",
      "Using 501 files for validation.\n",
      "Epoch 1/9\n",
      "63/63 [==============================] - 19s 225ms/step - loss: 0.9123 - accuracy: 0.6796 - val_loss: 0.4090 - val_accuracy: 0.8663\n",
      "Epoch 2/9\n",
      "63/63 [==============================] - 12s 193ms/step - loss: 0.3216 - accuracy: 0.8869 - val_loss: 0.2384 - val_accuracy: 0.9202\n",
      "Epoch 3/9\n",
      "63/63 [==============================] - 13s 196ms/step - loss: 0.1850 - accuracy: 0.9472 - val_loss: 0.1891 - val_accuracy: 0.9281\n",
      "Epoch 4/9\n",
      "63/63 [==============================] - 12s 191ms/step - loss: 0.1469 - accuracy: 0.9492 - val_loss: 0.1676 - val_accuracy: 0.9381\n",
      "Epoch 5/9\n",
      "63/63 [==============================] - 13s 203ms/step - loss: 0.0954 - accuracy: 0.9741 - val_loss: 0.1240 - val_accuracy: 0.9581\n",
      "Epoch 6/9\n",
      "63/63 [==============================] - 12s 191ms/step - loss: 0.0932 - accuracy: 0.9726 - val_loss: 0.2523 - val_accuracy: 0.9022\n",
      "Epoch 7/9\n",
      "63/63 [==============================] - 13s 197ms/step - loss: 0.0710 - accuracy: 0.9781 - val_loss: 0.1183 - val_accuracy: 0.9481\n",
      "Epoch 8/9\n",
      "63/63 [==============================] - 12s 189ms/step - loss: 0.0574 - accuracy: 0.9821 - val_loss: 0.0792 - val_accuracy: 0.9800\n",
      "Epoch 9/9\n",
      "63/63 [==============================] - 12s 183ms/step - loss: 0.0450 - accuracy: 0.9870 - val_loss: 0.0800 - val_accuracy: 0.9800\n",
      "Found 626 files belonging to 4 classes.\n",
      "20/20 [==============================] - 2s 95ms/step - loss: 0.0845 - accuracy: 0.9728\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.applications import DenseNet169\n",
    "\n",
    "# Betitelung für Tensorboard\n",
    "experiment_name = \"DenseNet169_Dataaug\"\n",
    "\n",
    "# Data Augmentation Layer hinzufügen\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),  # Rotation um bis zu 20%\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),  # Horizontaler und vertikaler Flip\n",
    "    tf.keras.layers.experimental.preprocessing.RandomContrast(0.1),  # Zufällige Kontrastanpassung\n",
    "])\n",
    "\n",
    "# Funktion zur Vorbereitung und Augmentation der Bilder\n",
    "def preprocess_and_augment_dataset(ds):\n",
    "    # Zuerst Data Augmentation anwenden\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "    # Dann die spezifische Vorverarbeitung für ResNet50 anwenden\n",
    "    return ds.map(lambda x, y: (preprocess_input(x), y))\n",
    "\n",
    "# Funktion zur Vorbereitung der Testdaten\n",
    "def preprocess_dataset(ds):\n",
    "    return ds.map(lambda x, y: (preprocess_input(x), y))    \n",
    "\n",
    "# Trainingsdaten laden und vorbereiten\n",
    "train_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "\n",
    "# Anwendung der Vorverarbeitung und Augmentation auf Trainingsdaten\n",
    "train_ds = preprocess_and_augment_dataset(train_ds)\n",
    "\n",
    "# Validierungsdaten laden und vorbereiten\n",
    "val_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "\n",
    "# Anwendung der Vorverarbeitung (ohne Augmentation) auf Validierungsdaten\n",
    "val_ds = preprocess_and_augment_dataset(val_ds) \n",
    "\n",
    "# Vortrainiertes Modell laden\n",
    "base_model = DenseNet169(input_shape=(224, 224, 3), include_top=False, weights='imagenet')  # DenseNet 161\n",
    "base_model.trainable = False  # Einfrieren der Basis-Schichten\n",
    "\n",
    "\n",
    "# Modell anpassen\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "outputs = Dense(4, activation='softmax')(x)  # 4 Klassen für Ihre Emotionen\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Modell kompilieren und trainieren\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Setze den Pfad für die TensorBoard Logs\n",
    "log_dir = \"logs/fit/\" + experiment_name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, update_freq=\"epoch\")\n",
    "\n",
    "model.fit(\n",
    "    train_ds, \n",
    "    validation_data=val_ds, \n",
    "    epochs=9, \n",
    "    callbacks=[tensorboard_callback]  # TensorBoard Callback hinzufügen\n",
    ")\n",
    "\n",
    "# Modell mit Testdaten testen\n",
    "test_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions_Test\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "test_ds = preprocess_dataset(test_ds)\n",
    "\n",
    "# Modell evaluieren\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "\n",
    "# Pfad für Test-Logs setzen\n",
    "test_log_dir = \"logs/fit/\" + experiment_name + \"_test_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Summary Writer für Testdaten erstellen\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "\n",
    "# Testmetriken in TensorBoard loggen\n",
    "with test_summary_writer.as_default():\n",
    "    tf.summary.scalar('test_loss', test_loss, step=0)\n",
    "    tf.summary.scalar('test_accuracy', test_accuracy, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EfficientNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2508 files belonging to 4 classes.\n",
      "Using 2007 files for training.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "Found 2508 files belonging to 4 classes.\n",
      "Using 501 files for validation.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.\n",
      "Epoch 1/9\n",
      "63/63 [==============================] - 44s 570ms/step - loss: 0.6926 - accuracy: 0.7140 - val_loss: 1.0211 - val_accuracy: 0.6108\n",
      "Epoch 2/9\n",
      "63/63 [==============================] - 35s 546ms/step - loss: 0.3700 - accuracy: 0.8490 - val_loss: 1.1269 - val_accuracy: 0.5948\n",
      "Epoch 3/9\n",
      "63/63 [==============================] - 33s 522ms/step - loss: 0.3082 - accuracy: 0.8839 - val_loss: 1.0546 - val_accuracy: 0.6507\n",
      "Epoch 4/9\n",
      "63/63 [==============================] - 34s 539ms/step - loss: 0.2674 - accuracy: 0.8959 - val_loss: 1.2849 - val_accuracy: 0.6347\n",
      "Epoch 5/9\n",
      "63/63 [==============================] - 34s 529ms/step - loss: 0.2323 - accuracy: 0.9063 - val_loss: 1.2901 - val_accuracy: 0.6547\n",
      "Epoch 6/9\n",
      "63/63 [==============================] - 32s 502ms/step - loss: 0.1951 - accuracy: 0.9233 - val_loss: 1.2130 - val_accuracy: 0.6467\n",
      "Epoch 7/9\n",
      "63/63 [==============================] - 32s 501ms/step - loss: 0.1835 - accuracy: 0.9278 - val_loss: 1.2837 - val_accuracy: 0.6427\n",
      "Epoch 8/9\n",
      "63/63 [==============================] - 32s 499ms/step - loss: 0.1819 - accuracy: 0.9243 - val_loss: 1.3370 - val_accuracy: 0.6766\n",
      "Epoch 9/9\n",
      "63/63 [==============================] - 33s 526ms/step - loss: 0.1387 - accuracy: 0.9447 - val_loss: 1.0936 - val_accuracy: 0.7026\n",
      "Found 626 files belonging to 4 classes.\n",
      "20/20 [==============================] - 5s 247ms/step - loss: 0.2848 - accuracy: 0.8754\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import EfficientNetB7  # Update für EfficientNetB7\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input  # Update für EfficientNet-spezifische preprocess_input-Funktion\n",
    "\n",
    "# Betitelung für Tensorboard\n",
    "experiment_name = \"EfficientNetB7_Dataaug\"\n",
    "\n",
    "# Data Augmentation Layer hinzufügen\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),  # Rotation um bis zu 20%\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),  # Horizontaler und vertikaler Flip\n",
    "    tf.keras.layers.experimental.preprocessing.RandomContrast(0.1),  # Zufällige Kontrastanpassung\n",
    "])\n",
    "\n",
    "\n",
    "# Funktion zur Vorbereitung und Augmentation der Bilder\n",
    "def preprocess_and_augment_dataset(ds):\n",
    "    # Zuerst Data Augmentation anwenden\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "    # Dann die spezifische Vorverarbeitung für ResNet50 anwenden\n",
    "    return ds.map(lambda x, y: (preprocess_input(x), y))\n",
    "\n",
    "# Funktion zur Vorbereitung der Testdaten\n",
    "def preprocess_dataset(ds):\n",
    "    return ds.map(lambda x, y: (preprocess_input(x), y))\n",
    "\n",
    "# Trainingsdaten laden und vorbereiten\n",
    "train_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "\n",
    "# Anwendung der Vorverarbeitung und Augmentation auf Trainingsdaten\n",
    "train_ds = preprocess_and_augment_dataset(train_ds)\n",
    "\n",
    "# Validierungsdaten laden und vorbereiten\n",
    "val_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "\n",
    "# Anwendung der Vorverarbeitung (ohne Augmentation) auf Validierungsdaten\n",
    "val_ds = preprocess_and_augment_dataset(val_ds) \n",
    "\n",
    "# Vortrainiertes Modell laden\n",
    "base_model = EfficientNetB7(input_shape=(224, 224, 3), include_top=False, weights='imagenet')  # Änderung zu EfficientNetB7\n",
    "base_model.trainable = False  # Einfrieren der Basis-Schichten\n",
    "\n",
    "# Modell anpassen\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "outputs = Dense(4, activation='softmax')(x)  # 4 Klassen für Ihre Emotionen\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Modell kompilieren und trainieren\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Setze den Pfad für die TensorBoard Logs\n",
    "log_dir = \"logs/fit/\" + experiment_name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, update_freq=\"epoch\")\n",
    "\n",
    "model.fit(\n",
    "    train_ds, \n",
    "    validation_data=val_ds, \n",
    "    epochs=9, \n",
    "    callbacks=[tensorboard_callback]  # TensorBoard Callback hinzufügen\n",
    ")\n",
    "\n",
    "# Modell mit Testdaten testen\n",
    "test_ds = image_dataset_from_directory(\n",
    "    \"C:\\\\Thesis\\\\Data\\\\Frames\\\\Facial_Expressions_Test\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32)\n",
    "test_ds = preprocess_dataset(test_ds)\n",
    "\n",
    "# Modell evaluieren\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "\n",
    "# Pfad für Test-Logs setzen\n",
    "test_log_dir = \"logs/fit/\" + experiment_name + \"_test_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Summary Writer für Testdaten erstellen\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "\n",
    "# Testmetriken in TensorBoard loggen\n",
    "with test_summary_writer.as_default():\n",
    "    tf.summary.scalar('test_loss', test_loss, step=0)\n",
    "    tf.summary.scalar('test_accuracy', test_accuracy, step=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
